{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 13\n",
    "\n",
    "## Analyze class homeworks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../datasets/Consolidado_respuestas_escribir_v2.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-2e0e75e33734>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../datasets/Consolidado_respuestas_escribir_v2.xlsx'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    206\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, verbose, parse_dates, date_parser, thousands, comment, skip_footer, skipfooter, convert_float, mangle_dupe_cols, **kwds)\u001b[0m\n\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 310\u001b[1;33m         \u001b[0mio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    311\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m         raise ValueError(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, io, engine)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_io\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_stringify_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engines\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__fspath__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_xlrd.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0merr_msg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Install xlrd >= 1.0.0 for Excel support\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mimport_optional_dependency\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"xlrd\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextra\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[0;32m    357\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 359\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    360\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m             raise ValueError(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_xlrd.py\u001b[0m in \u001b[0;36mload_workbook\u001b[1;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[0;32m     34\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mopen_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_contents\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mopen_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xlrd\\__init__.py\u001b[0m in \u001b[0;36mopen_workbook\u001b[1;34m(filename, logfile, verbosity, use_mmap, file_contents, encoding_override, formatting_info, on_demand, ragged_rows)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m             \u001b[0mpeek\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpeeksz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpeek\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34mb\"PK\\x03\\x04\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# a ZIP file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../datasets/Consolidado_respuestas_escribir_v2.xlsx'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = pd.read_excel('../datasets/Consolidado_respuestas_escribir_v2.xlsx')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 13.1\n",
    "\n",
    "Analyze the writing patterns of each student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "# from textblob import TextBlob, Word\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data[\"Longitud_E1\"] = data['E1 - Examples of Time Series Analysis'].str.split().str.len()\n",
    "data.Longitud_E1.describe(percentiles=[0.05, 0.1, 0.15, 0., .25, .5, .75, 0.9, 0.95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data[\"Longitud_E4\"] = data['E4 - Panel Data'].str.split().str.len()\n",
    "data.Longitud_E4.describe(percentiles=[0.05, 0.1, 0.15, 0., .25, .5, .75, 0.9, 0.95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Longitud_E6\"] = data['E6 - Decison Trees'].str.split().str.len()\n",
    "data.Longitud_E6.describe(percentiles=[0.05, 0.1, 0.15, 0., .25, .5, .75, 0.9, 0.95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Longitud_E8\"] = data['E8 - Ensemble Trees Overview'].str.split().str.len()\n",
    "data.Longitud_E8.describe(percentiles=[0.05, 0.1, 0.15, 0., .25, .5, .75, 0.9, 0.95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Longitud_E10\"] = data['E10 - REST-API'].str.split().str.len()\n",
    "data.Longitud_E10.describe(percentiles=[0.05, 0.1, 0.15, 0., .25, .5, .75, 0.9, 0.95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Longitud_E11\"] = data['E11 - Natural Language Processing Overview'].str.split().str.len()\n",
    "data.Longitud_E11.describe(percentiles=[0.05, 0.1, 0.15, 0., .25, .5, .75, 0.9, 0.95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Promedio de paralabras por estudiante\n",
    "data[\"Media\"] = data.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Tareas Faltantes\"] =data.isnull().sum(axis=1)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Identifica si la respuesta a cada tarea está en idioma inglés \n",
    "data['English_E1'] = np.where(data['E1 - Examples of Time Series Analysis'].str.contains(\"the\", case=False, na=False), 'T', 'F')\n",
    "data.loc[data[\"Longitud_E1\"] != data[\"Longitud_E1\"], \"English_E1\"] = np.nan \n",
    "\n",
    "data['English_E4'] = np.where(data['E4 - Panel Data'].str.contains(\"the\", case=False, na=False), 'T', 'F')\n",
    "data.loc[data[\"Longitud_E4\"] != data[\"Longitud_E4\"], \"English_E4\"] = np.nan \n",
    "\n",
    "data['English_E6'] = np.where(data['E6 - Decison Trees'].str.contains(\"the\", case=False, na=False), 'T', 'F')\n",
    "data.loc[data[\"Longitud_E6\"] != data[\"Longitud_E6\"], \"English_E6\"] = np.nan\n",
    "\n",
    "data['English_E8'] = np.where(data['E8 - Ensemble Trees Overview'].str.contains(\"the\", case=False, na=False), 'T', 'F')\n",
    "data.loc[data[\"Longitud_E8\"] != data[\"Longitud_E8\"], \"English_E8\"] = np.nan\n",
    "\n",
    "data['English_E10'] = np.where(data['E10 - REST-API'].str.contains(\"the\", case=False, na=False), 'T', 'F')\n",
    "data.loc[data[\"Longitud_E10\"] != data[\"Longitud_E10\"], \"English_E10\"] = np.nan\n",
    "\n",
    "data['English_E11'] = np.where(data['E11 - Natural Language Processing Overview'].str.contains(\"the\", case=False, na=False), 'T', 'F')\n",
    "data.loc[data[\"Longitud_E11\"] != data[\"Longitud_E11\"], \"English_E11\"] = np.nan\n",
    "\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Asigna labels a la variable \"GENERO\"\n",
    "Sex = {\"F\": 'Femenino', \"M\": 'Masculino'}\n",
    "data[\"Genero\"] = data[\"Genero\"].apply(lambda x: Sex[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.groupby(['Genero'])['Media'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gráfica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "titulos = ['E1 - Examples of Time Series Analysis', 'E4 - Panel Data', 'E6 - Decison Trees', 'E8 - Ensemble Trees Overview','E10 - REST-API','E11 - Natural Language Processing Overview' ]\n",
    "\n",
    "for i in range(7,13):\n",
    "\n",
    "    summary=data.iloc[:,[0,i]].dropna()\n",
    "    summary\n",
    "\n",
    "    SerieM = summary.loc[summary.Genero==\"Masculino\"]\n",
    "    SerieF = summary.loc[summary.Genero==\"Femenino\"]\n",
    "\n",
    "    SerieF = SerieF.iloc[:,[1]]\n",
    "    SerieM = SerieM.iloc[:,[1]]\n",
    "\n",
    "    plt.plot(SerieF,label=\"Femenino\")\n",
    "    plt.plot(SerieM,label=\"Masculino\")\n",
    "    plt.title(titulos[i-7])\n",
    "    plt.legend()\n",
    "    plt.xlabel('estudiante')\n",
    "    plt.ylabel('palabras por tarea')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "data.groupby(\"Genero\")[\"Media\"].plot(kind=\"hist\")\n",
    "plt.legend() # optional, but recommended\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.groupby(['Genero']).mean()['Media'].plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(data[\"Genero\"]).value_counts().plot(kind = \"bar\",figsize=(8,6),rot = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "data.groupby(['Genero','English_E1']).mean()['Longitud_E1'].unstack().plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "data.groupby(['Genero','English_E4']).mean()['Longitud_E4'].unstack().plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "data.groupby(['Genero','English_E6']).mean()['Longitud_E6'].unstack().plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "data.groupby(['Genero','English_E8']).mean()['Longitud_E8'].unstack().plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "data.groupby(['Genero','English_E10']).mean()['Longitud_E10'].unstack().plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "data.groupby(['Genero','English_E11']).mean()['Longitud_E11'].unstack().plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 13.2\n",
    "\n",
    "Evaluate the similarities of the homeworks of the students.\n",
    "\n",
    "At a homework level, then as a student level.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A nivel de tarea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(query, document):\n",
    "    intersection = set(query).intersection(set(document))\n",
    "    union = set(query).union(set(document))\n",
    "    return len(intersection)/len(union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "    Rta_estudiante=data.iloc[:,[1]]\n",
    "    print(Rta_estudiante)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    Rta_estudiante=data.iloc[11,[1]]\n",
    "    print(Rta_estudiante)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-4ad8f19bb64c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m46\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mRta_estudiante\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mserie\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRta_estudiante\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mserie\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "#list=()\n",
    "\n",
    "for i in range(0,46):\n",
    "    \n",
    "    Rta_estudiante=data.iloc[i,1]\n",
    "    serie.append(Rta_estudiante)\n",
    "print(serie)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(query, document):\n",
    "    intersection = set(query).intersection(set(document))\n",
    "    union = set(query).union(set(document))\n",
    "    return len(intersection)/len(union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The time series analysis is important because it help us to predict future events, through the use of a collection of data we can identify trends, cycles and seasonal variances. \\nBelow we can see 3 real life usages of time series analysis:\\n1. In Banking you can analyze the stability of the financial sector, through different indexes like Systemic Expected Shortfall. This index identifies which institutions are systemically relevant and the effects on the economy. So, with economic indicators you can predict the stability of the system and whether a bank is more or less stable than other. This is helpful when you are studying financial crisis.\\n2. Another usage of Time Series Analysis are models to estimate the interaction between manufacturing production and employment, this is helpful because manufacturing sector is one of the sectors that generates employment. The results may show you if these two variables are stationary and if the trends have a significant relationship, so policy makers can take actions to promote manufactured production to reduce unemployment rate.\\n3. Finally, one of the applications of Time Series Analysis are the models to predict the spot and forward prices in wholesale electricity markets. The electricity demand depends on multiple factors like weather and business activities, and this leads to price dynamics and high volatility. For example, in Europe electricity is traded under market rules, therefore as a manager is important to predict the price to make derivative contracts to balance the consumption. \\n'"
      ]
     },
     "execution_count": 534,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rta_estudiante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ANÁLISIS DE SERIES DE TIEMPO – USOS \\nEl análisis de series de tiempo permite realizar la descomposición de un conjunto de datos que ha sido recopilado de manera periódica (minuto a minuto, diaria, semanal, mensual, bimensual, semestral, etc.) por un periodo de tiempo, identificando sus componentes, a saber: Tendencia, Estacionalidad y Aleatoriedad. Esta descomposición permite tener conocimiento del comportamiento de la serie y a su vez permite modelarla para de esta manera obtener pronósticos sobre los valores futuros que podrá tomar la serie.   \\nUso 1:\\nLa compañía Onda de Mar se ha dedicado por más de 25 años al diseño, fabricación y distribución de trajes de baño, a lo largo de este tiempo como parte integral de sus estados financieros tienen registrado el total de ventas mensuales en Colombia.  El gerente de ventas ha recibido un informe sobre el histórico de ventas y se evidencia un lógico crecimiento en estas, en los periodos previos a las vacaciones (mayo y noviembre), teniendo en cuenta el informe que recibió el gerente, así como la serie de tiempo con datos mensuales sobre las ventas de todas las tiendas a nivel nacional, se quiere conocer el monto de ventas que se obtendrá en los próximos 6 meses.\\nUso 2:\\nEl Oceanic Niño Index -ONI- es un índice que mide el promedio, para los últimos 3 meses, de la temperatura sobre la superficie oceánica en la región Niño 3.4 (5°N-5°S, 120°-170°W) ubicada al este de nuestro país, en el Océano Pacífico y de acuerdo con la National Oceanic and Atmospheric Administration, se está en presencia de un fenómeno del Niño cuando se tiene una temperatura superior o igual al 0.5°C por mínimo 5 periodos -de 3 meses- consecutivos, por otro lado, el fenómeno de la Niña se presenta cuando esta temperatura es igual o inferior a -0.5°C por los mismos 5 periodos. Mediante TSA se busca identificar la temperatura para los próximos 6 periodos e identificar si se va presentar un fenómeno de Niño o de Niña.\\nUso 3:\\nEl Banco Mundial -BM- es una entidad multilateral que busca apoyar a los países miembros, a encontrar una solución para reducir la pobreza, así como a generar prosperidad en los países en desarrollo, esta labor se realiza mediante préstamos o apoyo con acompañamiento técnico para el desarrollo de proyectos o políticas encaminadas a lograr los objetivos antes descritos.  \\nPor otro lado, el BM es un ente que recopila información de variables económicas de distintos países a nivel mundial, como es el PIB que consiste en la suma del valor agregado bruto de todos los productores residentes en la economía más los impuestos a los productos y menos los subsidios no incluidos en el valor de los productos.  Es así como el BM tiene información histórica anual desde 1960 del PIB y mediante un TSA es posible obtener el pronóstico del PIB para años posteriores.'"
      ]
     },
     "execution_count": 511,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'reset_index'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-477-c8a97ff84893>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mRta_1_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'reset_index'"
     ]
    }
   ],
   "source": [
    "Rta_1_1.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'iloc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-531-1074d59b337c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mRta_1_1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mserie\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mRta_2_1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mserie\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'iloc'"
     ]
    }
   ],
   "source": [
    "Rta_1_1=data.iloc[0,1]\n",
    "Rta_2_1=data.iloc[1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E1 - Examples of Time Series Analysis    ANÁLISIS DE SERIES DE TIEMPO – USOS \\nEl análi...\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(Rta_1_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rta_1_1_s = \"ANÁLISIS DE SERIES DE TIEMPO – USOS \\nEl análisis de series de tiempo permite realizar la descomposición de un conjunto de datos que ha sido recopilado de manera periódica (minuto a minuto, diaria, semanal, mensual, bimensual, semestral, etc.) por un periodo de tiempo, identificando sus componentes, a saber: Tendencia, Estacionalidad y Aleatoriedad. Esta descomposición permite tener conocimiento del comportamiento de la serie y a su vez permite modelarla para de esta manera obtener pronósticos sobre los valores futuros que podrá tomar la serie.   \\nUso 1:\\nLa compañía Onda de Mar se ha dedicado por más de 25 años al diseño, fabricación y distribución de trajes de baño, a lo largo de este tiempo como parte integral de sus estados financieros tienen registrado el total de ventas mensuales en Colombia.  El gerente de ventas ha recibido un informe sobre el histórico de ventas y se evidencia un lógico crecimiento en estas, en los periodos previos a las vacaciones (mayo y noviembre), teniendo en cuenta el informe que recibió el gerente, así como la serie de tiempo con datos mensuales sobre las ventas de todas las tiendas a nivel nacional, se quiere conocer el monto de ventas que se obtendrá en los próximos 6 meses.\\nUso 2:\\nEl Oceanic Niño Index -ONI- es un índice que mide el promedio, para los últimos 3 meses, de la temperatura sobre la superficie oceánica en la región Niño 3.4 (5°N-5°S, 120°-170°W) ubicada al este de nuestro país, en el Océano Pacífico y de acuerdo con la National Oceanic and Atmospheric Administration, se está en presencia de un fenómeno del Niño cuando se tiene una temperatura superior o igual al 0.5°C por mínimo 5 periodos -de 3 meses- consecutivos, por otro lado, el fenómeno de la Niña se presenta cuando esta temperatura es igual o inferior a -0.5°C por los mismos 5 periodos. Mediante TSA se busca identificar la temperatura para los próximos 6 periodos e identificar si se va presentar un fenómeno de Niño o de Niña.\\nUso 3:\\nEl Banco Mundial -BM- es una entidad multilateral que busca apoyar a los países miembros, a encontrar una solución para reducir la pobreza, así como a generar prosperidad en los países en desarrollo, esta labor se realiza mediante préstamos o apoyo con acompañamiento técnico para el desarrollo de proyectos o políticas encaminadas a lograr los objetivos antes descritos.  \\nPor otro lado, el BM es un ente que recopila información de variables económicas de distintos países a nivel mundial, como es el PIB que consiste en la suma del valor agregado bruto de todos los productores residentes en la economía más los impuestos a los productos y menos los subsidios no incluidos en el valor de los productos.  Es así como el BM tiene información histórica anual desde 1960 del PIB y mediante un TSA es posible obtener el pronóstico del PIB para años posteriores.\"\n",
    "Rta_2_1_s = \"Los análisis de series de tiempo son tecnicas\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANÁLISIS DE SERIES DE TIEMPO – USOS \n",
      "El análisis de series de tiempo permite realizar la descomposición de un conjunto de datos que ha sido recopilado de manera periódica (minuto a minuto, diaria, semanal, mensual, bimensual, semestral, etc.) por un periodo de tiempo, identificando sus componentes, a saber: Tendencia, Estacionalidad y Aleatoriedad. Esta descomposición permite tener conocimiento del comportamiento de la serie y a su vez permite modelarla para de esta manera obtener pronósticos sobre los valores futuros que podrá tomar la serie.   \n",
      "Uso 1:\n",
      "La compañía Onda de Mar se ha dedicado por más de 25 años al diseño, fabricación y distribución de trajes de baño, a lo largo de este tiempo como parte integral de sus estados financieros tienen registrado el total de ventas mensuales en Colombia.  El gerente de ventas ha recibido un informe sobre el histórico de ventas y se evidencia un lógico crecimiento en estas, en los periodos previos a las vacaciones (mayo y noviembre), teniendo en cuenta el informe que recibió el gerente, así como la serie de tiempo con datos mensuales sobre las ventas de todas las tiendas a nivel nacional, se quiere conocer el monto de ventas que se obtendrá en los próximos 6 meses.\n",
      "Uso 2:\n",
      "El Oceanic Niño Index -ONI- es un índice que mide el promedio, para los últimos 3 meses, de la temperatura sobre la superficie oceánica en la región Niño 3.4 (5°N-5°S, 120°-170°W) ubicada al este de nuestro país, en el Océano Pacífico y de acuerdo con la National Oceanic and Atmospheric Administration, se está en presencia de un fenómeno del Niño cuando se tiene una temperatura superior o igual al 0.5°C por mínimo 5 periodos -de 3 meses- consecutivos, por otro lado, el fenómeno de la Niña se presenta cuando esta temperatura es igual o inferior a -0.5°C por los mismos 5 periodos. Mediante TSA se busca identificar la temperatura para los próximos 6 periodos e identificar si se va presentar un fenómeno de Niño o de Niña.\n",
      "Uso 3:\n",
      "El Banco Mundial -BM- es una entidad multilateral que busca apoyar a los países miembros, a encontrar una solución para reducir la pobreza, así como a generar prosperidad en los países en desarrollo, esta labor se realiza mediante préstamos o apoyo con acompañamiento técnico para el desarrollo de proyectos o políticas encaminadas a lograr los objetivos antes descritos.  \n",
      "Por otro lado, el BM es un ente que recopila información de variables económicas de distintos países a nivel mundial, como es el PIB que consiste en la suma del valor agregado bruto de todos los productores residentes en la economía más los impuestos a los productos y menos los subsidios no incluidos en el valor de los productos.  Es así como el BM tiene información histórica anual desde 1960 del PIB y mediante un TSA es posible obtener el pronóstico del PIB para años posteriores.\n"
     ]
    }
   ],
   "source": [
    "print(Rta_1_1_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "E1 - Examples of Time Series Analysis    Los análisis de series de tiempo son tecnicas ...\n",
       "Name: 41, dtype: object"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rta_2_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5616438356164384"
      ]
     },
     "execution_count": 529,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jaccard_similarity(Rta_1_1, Rta_2_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tarea = ['E1 - Examples of Time Series Analysis', 'E4 - Panel Data', 'E6 - Decison Trees', 'E8 - Ensemble Trees Overview','E10 - REST-API','E11 - Natural Language Processing Overview' ]\n",
    "serie []\n",
    "\n",
    "for i in range(1,6):\n",
    "\n",
    "    summary=data.iloc[:,[0,i]].dropna()\n",
    "    summary\n",
    "\n",
    "    Tarea = summary.loc[summary.Genero==\"Masculino\"]\n",
    "    SerieF = summary.loc[summary.Genero==\"Femenino\"]\n",
    "\n",
    "    SerieF = SerieF.iloc[:,[1]]\n",
    "    SerieM = SerieM.iloc[:,[1]]\n",
    "\n",
    "    plt.plot(SerieF,label=\"Femenino\")\n",
    "    plt.plot(SerieM,label=\"Masculino\")\n",
    "    plt.title(titulos[i-7])\n",
    "    plt.legend()\n",
    "    plt.xlabel('estudiante')\n",
    "    plt.ylabel('palabras por tarea')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "s1_1 = \"AI is our friend and it has been friendly\" #Respuesta tarea 1 estudiante 1\n",
    "s1_2 = \"AI is our friend and it has been friendly\" #Respuesta tarea 1 estudiante 2\n",
    ".\n",
    ".\n",
    ".\n",
    "\n",
    "s2 = \"AI and humans have always been friendly\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaccard_similarity(s1, s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 13.3\n",
    "\n",
    "Create a classifier to predict the gender of each student\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 13.4\n",
    "Classify group members into different subgroups (minimum 3) according to a characteristic of your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
